example:  Example: 
{
    "p_id": 6,
    "context": "ç¦…æ„æ­Œè€…åˆ˜ç‚çŸ£ã€Šä¸€è¢–äº‘ã€‹ä¸­è¯‰çŸ¥å·±â€¦ç»µæŸ”çº¯å‡€çš„å¥³å£°ï¼Œå°†å¿ƒä¸­çš„ä¸‡æ°´åƒå±±å°½æ„å‹¾å‹’äºè¿™æ¸…ç´ ç”»éŸ³ä¸­",
    "raw_context": null,
    "text_word": [
        "ç¦…æ„",
        "æ­Œè€…",
        "åˆ˜ç‚",
        "çŸ£",
        "ã€Š",
        "ä¸€è¢–",
        "äº‘",
        "ã€‹",
        "ä¸­è¯‰",
        "çŸ¥å·±",
        "â€¦",
        "ç»µæŸ”",
        "çº¯å‡€",
        "çš„",
        "å¥³å£°",
        "ï¼Œ",
        "å°†",
        "å¿ƒä¸­",
        "çš„",
        "ä¸‡æ°´åƒå±±",
        "å°½æ„",
        "å‹¾å‹’",
        "äº",
        "è¿™",
        "æ¸…ç´ ",
        "ç”»éŸ³",
        "ä¸­"
    ],
    "bert_tokens": null,
    "entity_list": [
        "ä¸€è¢–äº‘",
        "åˆ˜ç‚çŸ£"
    ],
    "gold_answer": [
        [
            "ä¸€è¢–äº‘",
            "æ­Œæ‰‹",
            "åˆ˜ç‚çŸ£"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 44]) 
 tensor([[1944,  445,   45,   50,  166, 1926, 3351,    7,   15, 1980,  345,    8,
           17, 1586,  395,  443, 1671, 1910, 1297, 1040, 1906,    4,   78,  544,
            3,  364,  156,   17,    4,  385,  330,  590,  127, 1184,  445, 2615,
         1110,   20,  123,  350, 1001,  371,  224,   17]])
batch_word_ids: shape= torch.Size([1, 44]) 
 tensor([[21862, 21862, 10142, 10142, 15275, 15275,  9236,     3,     0,     0,
          1392,     4,     0,     0,  8339,  8339,  1036,     0,     0, 12910,
         12910,     2,  7602,  7602,     1,   131,  1419,  1419,     2, 15857,
         15857, 15857, 15857,     0,     0, 17142, 17142,    10,    96,     0,
             0,     0,     0,    22]])
batch_ent_labels: shape= torch.Size([1, 44]) 
 tensor([[0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 44, 49, 44]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
(4, <class 'tuple'>)
mhs with w2v
using BertAdam
example:  Example: 
{
    "p_id": 5,
    "context": "ã€Šé€é£è¡Œã€‹æ˜¯ç™¾åº¦æ–‡å­¦æ——ä¸‹çºµæ¨ªä¸­æ–‡ç½‘ç­¾çº¦ä½œå®¶æ¸…æ°´ç§‹é£åˆ›ä½œçš„ä¸€éƒ¨ä¸œæ–¹ç„å¹»å°è¯´ï¼Œå°è¯´å·²äº2014-04-28æ­£å¼å‘å¸ƒ",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "é€",
        "é£è¡Œ",
        "ã€‹",
        "æ˜¯",
        "ç™¾åº¦",
        "æ–‡å­¦",
        "æ——ä¸‹",
        "çºµæ¨ª",
        "ä¸­æ–‡ç½‘",
        "ç­¾çº¦",
        "ä½œå®¶",
        "æ¸…æ°´",
        "ç§‹é£",
        "åˆ›ä½œ",
        "çš„",
        "ä¸€éƒ¨",
        "ä¸œæ–¹",
        "ç„å¹»",
        "å°è¯´",
        "ï¼Œ",
        "å°è¯´",
        "å·²äº",
        "2014",
        "-",
        "04",
        "-",
        "28",
        "æ­£å¼",
        "å‘å¸ƒ"
    ],
    "bert_tokens": null,
    "entity_list": [
        "é€é£è¡Œ",
        "çºµæ¨ªä¸­æ–‡ç½‘",
        "é€é£è¡Œ",
        "æ¸…æ°´ç§‹é£"
    ],
    "gold_answer": [
        [
            "é€é£è¡Œ",
            "è¿è½½ç½‘ç«™",
            "çºµæ¨ªä¸­æ–‡ç½‘"
        ],
        [
            "é€é£è¡Œ",
            "ä½œè€…",
            "æ¸…æ°´ç§‹é£"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 55]) 
 tensor([[   7, 1650,  268,  105,    8,    6,  483,  349,   47,   19,  787,  194,
          862,  749,   17,   47,   56,  928,  447,   14,   52,  350,  330,  702,
          268,  126,   14,    4,   15,   74,  109,  206,  861,  556,   27,   43,
            3,   27,   43,  407,   20,   12,    9,    5,   46,  130,    9,   46,
          130,   12,   28,  258,  420,   73,  315]])
batch_word_ids: shape= torch.Size([1, 55]) 
 tensor([[    3,     0, 14726, 14726,     4,     5,   611,   611,   284,   284,
           421,   421,   344,   344,   122,   122,   122,   412,   412,   244,
           244,  6724,  6724, 13304, 13304,    57,    57,     2,     0,     0,
           489,   489,   704,   704,    41,    41,     1,    41,    41,   628,
           628,   133,   133,   133,   133,    36,   549,   549,    36,   425,
           425,   208,   208,   393,   393]])
batch_ent_labels: shape= torch.Size([1, 55]) 
 tensor([[0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 2, 2,
         2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 55, 49, 55]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 55, 49, 55])
selection_logits.shape =  torch.Size([1, 55, 49, 55])
mask.shape =  torch.Size([1, 55])
mask.unsqueeze(2).shape =  torch.Size([1, 55, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 55])
product:  torch.Size([1, 55, 1, 55])
selection_mask.shape =  torch.Size([1, 55, 49, 55])
selection_loss.shape =  torch.Size([1, 55, 49, 55])
selection_loss.shape =  torch.Size([148225])
selection_loss =  tensor(122523.8359, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(2227.7061, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(55, device='cuda:0')
example:  Example: 
{
    "p_id": 6,
    "context": "ç¦…æ„æ­Œè€…åˆ˜ç‚çŸ£ã€Šä¸€è¢–äº‘ã€‹ä¸­è¯‰çŸ¥å·±â€¦ç»µæŸ”çº¯å‡€çš„å¥³å£°ï¼Œå°†å¿ƒä¸­çš„ä¸‡æ°´åƒå±±å°½æ„å‹¾å‹’äºè¿™æ¸…ç´ ç”»éŸ³ä¸­",
    "raw_context": "ç¦…æ„æ­Œè€…åˆ˜ç‚çŸ£ã€Šä¸€è¢–äº‘ã€‹ä¸­è¯‰çŸ¥å·±â€¦ç»µæŸ”çº¯å‡€çš„å¥³å£°ï¼Œå°†å¿ƒä¸­çš„ä¸‡æ°´åƒå±±å°½æ„å‹¾å‹’äºè¿™æ¸…ç´ ç”»éŸ³ä¸­",
    "text_word": [
        "ç¦…æ„",
        "æ­Œè€…",
        "åˆ˜ç‚",
        "çŸ£",
        "ã€Š",
        "ä¸€è¢–",
        "äº‘",
        "ã€‹",
        "ä¸­è¯‰",
        "çŸ¥å·±",
        "â€¦",
        "ç»µæŸ”",
        "çº¯å‡€",
        "çš„",
        "å¥³å£°",
        "ï¼Œ",
        "å°†",
        "å¿ƒä¸­",
        "çš„",
        "ä¸‡æ°´åƒå±±",
        "å°½æ„",
        "å‹¾å‹’",
        "äº",
        "è¿™",
        "æ¸…ç´ ",
        "ç”»éŸ³",
        "ä¸­"
    ],
    "bert_tokens": null,
    "entity_list": [
        "ä¸€è¢–äº‘",
        "åˆ˜ç‚çŸ£"
    ],
    "gold_answer": [
        [
            "ä¸€è¢–äº‘",
            "æ­Œæ‰‹",
            "åˆ˜ç‚çŸ£"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 44]) 
 tensor([[1944,  445,   45,   50,  166, 1926, 3351,    7,   15, 1980,  345,    8,
           17, 1586,  395,  443, 1671, 1910, 1297, 1040, 1906,    4,   78,  544,
            3,  364,  156,   17,    4,  385,  330,  590,  127, 1184,  445, 2615,
         1110,   20,  123,  350, 1001,  371,  224,   17]])
batch_word_ids: shape= torch.Size([1, 44]) 
 tensor([[21862, 21862, 10142, 10142, 15275, 15275,  9236,     3,     0,     0,
          1392,     4,     0,     0,  8339,  8339,  1036,     0,     0, 12910,
         12910,     2,  7602,  7602,     1,   131,  1419,  1419,     2, 15857,
         15857, 15857, 15857,     0,     0, 17142, 17142,    10,    96,     0,
             0,     0,     0,    22]])
batch_ent_labels: shape= torch.Size([1, 44]) 
 tensor([[0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 44, 49, 44]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 44, 49, 44])
selection_logits.shape =  torch.Size([1, 44, 49, 44])
mask.shape =  torch.Size([1, 44])
mask.unsqueeze(2).shape =  torch.Size([1, 44, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 44])
product:  torch.Size([1, 44, 1, 44])
selection_mask.shape =  torch.Size([1, 44, 49, 44])
selection_loss.shape =  torch.Size([1, 44, 49, 44])
selection_loss.shape =  torch.Size([94864])
selection_loss =  tensor(78949.3281, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(1794.3029, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(44, device='cuda:0')
example:  Example: 
{
    "p_id": 3,
    "context": "ä¸è§’è—ç§‘ï¼Œoedipodidaeï¼Œæ˜†è™«çº²ç›´ç¿…ç›®è—æ€»ç§‘çš„ä¸€ä¸ªç§‘",
    "raw_context": null,
    "text_word": [
        "ä¸è§’",
        "è—ç§‘",
        "ï¼Œ",
        "oedipodidae",
        "ï¼Œ",
        "æ˜†è™«",
        "çº²",
        "ç›´ç¿…ç›®",
        "è—",
        "æ€»ç§‘",
        "çš„",
        "ä¸€ä¸ª",
        "ç§‘"
    ],
    "bert_tokens": null,
    "entity_list": [
        "ä¸è§’è—ç§‘",
        "ç›´ç¿…ç›®"
    ],
    "gold_answer": [
        [
            "ä¸è§’è—ç§‘",
            "ç›®",
            "ç›´ç¿…ç›®"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 30]) 
 tensor([[ 955,  366, 2352,   64,    3,   77,   57,  225,   69,  245,   77,  225,
           69,  225,   49,   57,    3,  744,  634,  530,  482,  559,  119, 2352,
          288,   64,    4,   15,   79,   64]])
batch_word_ids: shape= torch.Size([1, 30]) 
 tensor([[   0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    1,  413,  413,  278, 3480, 3480, 3480, 5232,
            0,    0,    2,   70,   70,  148]])
batch_ent_labels: shape= torch.Size([1, 30]) 
 tensor([[1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0,
         0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 30, 49, 30]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 30, 49, 30])
selection_logits.shape =  torch.Size([1, 30, 49, 30])
mask.shape =  torch.Size([1, 30])
mask.unsqueeze(2).shape =  torch.Size([1, 30, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 30])
product:  torch.Size([1, 30, 1, 30])
selection_mask.shape =  torch.Size([1, 30, 49, 30])
selection_loss.shape =  torch.Size([1, 30, 49, 30])
selection_loss.shape =  torch.Size([44100])
selection_loss =  tensor(34479.0078, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(1149.3003, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(30, device='cuda:0')
example:  Example: 
{
    "p_id": 2,
    "context": "èŒ¶æ ‘èŒ¶ç½‘è½ï¼Œstephanitischinensisdrakeï¼Œå±åŠç¿…ç›®ç½‘è½ç§‘å† ç½‘æ¤¿å±çš„ä¸€ç§æ˜†è™«",
    "raw_context": null,
    "text_word": [
        "èŒ¶æ ‘",
        "èŒ¶ç½‘",
        "è½",
        "ï¼Œ",
        "stephanitischinensisdrake",
        "ï¼Œ",
        "å±",
        "åŠç¿…ç›®",
        "ç½‘",
        "è½",
        "ç§‘å† ",
        "ç½‘æ¤¿å±",
        "çš„",
        "ä¸€ç§",
        "æ˜†è™«"
    ],
    "bert_tokens": null,
    "entity_list": [
        "èŒ¶æ ‘èŒ¶ç½‘è½",
        "åŠç¿…ç›®"
    ],
    "gold_answer": [
        [
            "èŒ¶æ ‘èŒ¶ç½‘è½",
            "ç›®",
            "åŠç¿…ç›®"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 48]) 
 tensor([[1374,  833, 1374,   56, 2060,    3,   85,  114,   57,  245,  209,   49,
           80,   69,  114,   69,   85,  122,  209,   69,   80,   57,   80,   85,
           69,   85,  225,   92,   49,  148,   57,    3,  190,  793,  559,  119,
           56, 2060,   64,  770,   56, 3285,  190,    4,   15,  249,  744,  634]])
batch_word_ids: shape= torch.Size([1, 48]) 
 tensor([[26475, 26475,     0,     0,  1679,     1,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     1,    98,  2642,  2642,  2642,   967,  1679,     0,     0,
             0,     0,     0,     2,     0,     0,   413,   413]])
batch_ent_labels: shape= torch.Size([1, 48]) 
 tensor([[1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 48, 49, 48]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 48, 49, 48])
selection_logits.shape =  torch.Size([1, 48, 49, 48])
mask.shape =  torch.Size([1, 48])
mask.unsqueeze(2).shape =  torch.Size([1, 48, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 48])
product:  torch.Size([1, 48, 1, 48])
selection_mask.shape =  torch.Size([1, 48, 49, 48])
selection_loss.shape =  torch.Size([1, 48, 49, 48])
selection_loss.shape =  torch.Size([112896])
selection_loss =  tensor(85107.6406, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(1773.0758, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(48, device='cuda:0')
example:  Example: 
{
    "p_id": 4,
    "context": "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯ï¼ˆ1986-ï¼‰ï¼Œæ˜¯ä¸€ä½èº«é«˜åªæœ‰70å…¬åˆ†å“¥ä¼¦æ¯”äºšç”·å­ï¼Œä½“é‡10å…¬æ–¤ï¼Œåªæ¯”éšèº«è¡Œæé«˜ä¸€äº›ï¼Œ2010å¹´è·å‰å°¼æ–¯ä¸–ç•Œçºªå½•æ­£å¼è®¤è¯ï¼Œæˆä¸ºå…¨çƒå½“ä»Šæœ€çŸ®çš„æˆå¹´ç”·äºº",
    "raw_context": null,
    "text_word": [
        "çˆ±å¾·å",
        "Â·",
        "å°¼ç§‘",
        "Â·",
        "åŸƒå°”å—",
        "è¿ªæ–¯",
        "ï¼ˆ",
        "1986",
        "-",
        "ï¼‰",
        "ï¼Œ",
        "æ˜¯",
        "ä¸€ä½",
        "èº«é«˜",
        "åªæœ‰",
        "70",
        "å…¬åˆ†",
        "å“¥ä¼¦æ¯”äºš",
        "ç”·å­",
        "ï¼Œ",
        "ä½“é‡",
        "10",
        "å…¬æ–¤",
        "ï¼Œ",
        "åª",
        "æ¯”",
        "éšèº«è¡Œæ",
        "é«˜",
        "ä¸€äº›",
        "ï¼Œ",
        "2010",
        "å¹´",
        "è·",
        "å‰å°¼æ–¯ä¸–ç•Œçºªå½•",
        "æ­£å¼",
        "è®¤è¯",
        "ï¼Œ",
        "æˆä¸º",
        "å…¨çƒ",
        "å½“ä»Š",
        "æœ€çŸ®",
        "çš„",
        "æˆå¹´",
        "ç”·äºº"
    ],
    "bert_tokens": null,
    "entity_list": [
        "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
        "70å…¬åˆ†",
        "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
        "1986",
        "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
        "å“¥ä¼¦æ¯”äºš"
    ],
    "gold_answer": [
        [
            "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
            "èº«é«˜",
            "70å…¬åˆ†"
        ],
        [
            "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
            "å‡ºç”Ÿæ—¥æœŸ",
            "1986"
        ],
        [
            "çˆ±å¾·åÂ·å°¼ç§‘Â·åŸƒå°”å—è¿ªæ–¯",
            "å›½ç±",
            "å“¥ä¼¦æ¯”äºš"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 86]) 
 tensor([[  91,  219,  134,   83,  488,   64,   83, 1233,  204,  104,  688,  163,
           54,    5,   13,   28,   34,  130,   55,    3,    6,   15,  153,  232,
          103,  591,   31,   29,    9,   38,  187,  734,  493,  415,  213,   93,
           66,    3,  254,  234,    5,    9,   38, 1347,    3,  591,  415,  791,
          232,  105,  101,  103,   15,  721,    3,   12,    9,    5,    9,   10,
          376,  537,  488,  163,  189,  351,  458,  181,  258,  420,  711,  959,
            3,   58,   51,  222,  186,  255,  391,  161, 3095,    4,   58,   10,
           93,   18]])
batch_word_ids: shape= torch.Size([1, 86]) 
 tensor([[ 4821,  4821,  4821,    21, 28463, 28463,    21, 41998, 41998, 41998,
         37365, 37365,    14,   379,   379,   379,   379,    36,    15,     1,
             5,     0,     0,   130,   130,   791,   791,  1707,  1707,  4468,
          4468,  3039,  3039,  3039,  3039,  1741,  1741,     1,   207,   207,
            67,    67,   724,   724,     1,   750,   627,     0,     0,     0,
             0,   347,   815,   815,     1,   114,   114,   114,   114,     7,
           342, 26476, 26476, 26476, 26476, 26476, 26476, 26476,   208,   208,
          3091,  3091,     1,   169,   169,   632,   632,  7601,  7601, 37366,
         37366,     2,  8026,  8026,   732,   732]])
batch_ent_labels: shape= torch.Size([1, 86]) 
 tensor([[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 1, 2, 2, 2, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 86, 49, 86]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 86, 49, 86])
selection_logits.shape =  torch.Size([1, 86, 49, 86])
mask.shape =  torch.Size([1, 86])
mask.unsqueeze(2).shape =  torch.Size([1, 86, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 86])
product:  torch.Size([1, 86, 1, 86])
selection_mask.shape =  torch.Size([1, 86, 49, 86])
selection_loss.shape =  torch.Size([1, 86, 49, 86])
selection_loss.shape =  torch.Size([362404])
selection_loss =  tensor(260882.5469, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(3033.5181, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(86, device='cuda:0')
example:  Example: 
{
    "p_id": 1,
    "context": "å¦‚ä½•æ¼”å¥½è‡ªå·±çš„è§’è‰²ï¼Œè¯·è¯»ã€Šæ¼”å‘˜è‡ªæˆ‘ä¿®å…»ã€‹ã€Šå–œå‰§ä¹‹ç‹ã€‹å‘¨æ˜Ÿé©°å´›èµ·äºç©·å›°æ½¦å€’ä¹‹ä¸­çš„ç‹¬é—¨ç§˜ç¬ˆ",
    "raw_context": null,
    "text_word": [
        "å¦‚ä½•",
        "æ¼”",
        "å¥½",
        "è‡ªå·±",
        "çš„",
        "è§’è‰²",
        "ï¼Œ",
        "è¯·è¯»",
        "ã€Š",
        "æ¼”å‘˜",
        "è‡ªæˆ‘",
        "ä¿®å…»",
        "ã€‹",
        "ã€Š",
        "å–œå‰§ä¹‹ç‹",
        "ã€‹",
        "å‘¨æ˜Ÿé©°",
        "å´›èµ·",
        "äº",
        "ç©·å›°æ½¦å€’",
        "ä¹‹ä¸­",
        "çš„",
        "ç‹¬é—¨",
        "ç§˜ç¬ˆ"
    ],
    "bert_tokens": null,
    "entity_list": [
        "å–œå‰§ä¹‹ç‹",
        "å‘¨æ˜Ÿé©°"
    ],
    "gold_answer": [
        [
            "å–œå‰§ä¹‹ç‹",
            "ä¸»æ¼”",
            "å‘¨æ˜Ÿé©°"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 43]) 
 tensor([[ 312,  481,   23,  246,  125,  443,    4,  366,  347,    3, 1039,  563,
            7,   23,   95,  125,  106,  675,  947,    8,    7,  338,   35,   75,
           81,    8,  242,  277, 1315, 2586,  215,   20, 2303, 2024, 5104, 1614,
           75,   17,    4,  597,  332,  958, 3725]])
batch_word_ids: shape= torch.Size([1, 43]) 
 tensor([[ 1335,  1335,  1015,   167,   109,   109,     2,   291,   291,     1,
             0,     0,     3,   182,   182,  2850,  2850, 14197, 14197,     4,
             3,  2340,  2340,  2340,  2340,     4,   825,   825,   825,  3403,
          3403,    10,     0,     0,     0,     0,  1244,  1244,     2,     0,
             0, 12178, 12178]])
batch_ent_labels: shape= torch.Size([1, 43]) 
 tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2,
         2, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])
batch_rel_labels: shape= torch.Size([1, 43, 49, 43]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 43, 49, 43])
selection_logits.shape =  torch.Size([1, 43, 49, 43])
mask.shape =  torch.Size([1, 43])
mask.unsqueeze(2).shape =  torch.Size([1, 43, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 43])
product:  torch.Size([1, 43, 1, 43])
selection_mask.shape =  torch.Size([1, 43, 49, 43])
selection_loss.shape =  torch.Size([1, 43, 49, 43])
selection_loss.shape =  torch.Size([90601])
selection_loss =  tensor(62700.1953, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(1458.1440, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(43, device='cuda:0')
example:  Example: 
{
    "p_id": 7,
    "context": "å—è¿¦å¸•å°”å·´ç‰¹å³°ï¼Œ8125ç±³",
    "raw_context": null,
    "text_word": [
        "å—è¿¦",
        "å¸•å°”å·´",
        "ç‰¹å³°",
        "ï¼Œ",
        "8125",
        "ç±³"
    ],
    "bert_tokens": null,
    "entity_list": [
        "å—è¿¦å¸•å°”å·´ç‰¹å³°",
        "8125ç±³"
    ],
    "gold_answer": [
        [
            "å—è¿¦å¸•å°”å·´ç‰¹å³°",
            "æµ·æ‹”",
            "8125ç±³"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 13]) 
 tensor([[ 104, 3185, 1461,  204,  508,  211,  531,    3,   28,    5,   12,   39,
          348]])
batch_word_ids: shape= torch.Size([1, 13]) 
 tensor([[  0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0, 327]])
batch_ent_labels: shape= torch.Size([1, 13]) 
 tensor([[1, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2]])
batch_rel_labels: shape= torch.Size([1, 13, 49, 13]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 13, 49, 13])
selection_logits.shape =  torch.Size([1, 13, 49, 13])
mask.shape =  torch.Size([1, 13])
mask.unsqueeze(2).shape =  torch.Size([1, 13, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 13])
product:  torch.Size([1, 13, 1, 13])
selection_mask.shape =  torch.Size([1, 13, 49, 13])
selection_loss.shape =  torch.Size([1, 13, 49, 13])
selection_loss.shape =  torch.Size([8281])
selection_loss =  tensor(5895.0576, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(453.4660, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(13, device='cuda:0')
example:  Example: 
{
    "p_id": 8,
    "context": "ã€Šèº«å¤–èº«æ¢¦ä¸­æ¢¦ã€‹æ˜¯è¿è½½äºæ™‹æ±Ÿæ–‡å­¦åŸçš„ä¸€éƒ¨åŸåˆ›ç±»å°è¯´ï¼Œä½œè€…æ˜¯è‹ç”Ÿç¬‘",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "èº«å¤–",
        "èº«æ¢¦ä¸­",
        "æ¢¦",
        "ã€‹",
        "æ˜¯",
        "è¿è½½",
        "äº",
        "æ™‹æ±Ÿ",
        "æ–‡å­¦åŸ",
        "çš„",
        "ä¸€éƒ¨",
        "åŸåˆ›",
        "ç±»",
        "å°è¯´",
        "ï¼Œ",
        "ä½œè€…",
        "æ˜¯",
        "è‹ç”Ÿ",
        "ç¬‘"
    ],
    "bert_tokens": null,
    "entity_list": [
        "èº«å¤–èº«æ¢¦ä¸­æ¢¦",
        "è‹ç”Ÿç¬‘"
    ],
    "gold_answer": [
        [
            "èº«å¤–èº«æ¢¦ä¸­æ¢¦",
            "ä½œè€…",
            "è‹ç”Ÿç¬‘"
        ]
    ]
}
batch_char_ids: shape= torch.Size([1, 32]) 
 tensor([[   7,  232,  341,  232,  468,   17,  468,    8,    6,  137,  200,   20,
          611,  111,   47,   19,  248,    4,   15,   74,  239,  126,  284,   27,
           43,    3,   14,   50,    6, 1611,   26,  682]])
batch_word_ids: shape= torch.Size([1, 32]) 
 tensor([[    3,     0,     0,     0,     0,     0,   610,     4,     5,    50,
            50,    10,   308,   308,     0,     0,     0,     2,     0,     0,
           561,   561,   228,    41,    41,     1,    16,    16,     5, 15276,
         15276,  1132]])
batch_ent_labels: shape= torch.Size([1, 32]) 
 tensor([[0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 1, 2, 2]])
batch_rel_labels: shape= torch.Size([1, 32, 49, 32]) 
 tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         ...,

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]],

         [[0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          ...,
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.],
          [0., 0., 0.,  ..., 0., 0., 0.]]]])
selection_logits.shape =  torch.Size([1, 32, 49, 32])
selection_logits.shape =  torch.Size([1, 32, 49, 32])
mask.shape =  torch.Size([1, 32])
mask.unsqueeze(2).shape =  torch.Size([1, 32, 1])
mask.unsqueeze(1).shape =  torch.Size([1, 1, 32])
product:  torch.Size([1, 32, 1, 32])
selection_mask.shape =  torch.Size([1, 32, 49, 32])
selection_loss.shape =  torch.Size([1, 32, 49, 32])
selection_loss.shape =  torch.Size([50176])
selection_loss =  tensor(33229.6289, device='cuda:0', grad_fn=<SumBackward0>)
selection_loss =  tensor(1038.4259, device='cuda:0', grad_fn=<DivBackward0>)
selection_mask.sum =  tensor(32, device='cuda:0')

0it [00:00, ?it/s][Aexample:  Example: 
{
    "p_id": 1,
    "context": "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯ï¼ˆcharlesarÃ¡nguizï¼‰ï¼Œ1989å¹´4æœˆ17æ—¥å‡ºç”Ÿäºæ™ºåˆ©åœ£åœ°äºšå“¥ï¼Œæ™ºåˆ©èŒä¸šè¶³çƒè¿åŠ¨å‘˜ï¼Œå¸èŒä¸­åœºï¼Œæ•ˆåŠ›äºå¾·å›½è¶³çƒç”²çº§è”èµ›å‹’æ²ƒåº“æ£®è¶³çƒä¿±ä¹éƒ¨",
    "raw_context": null,
    "text_word": [
        "æŸ¥å°”æ–¯",
        "Â·",
        "é˜¿å…°",
        "åŸºæ–¯",
        "ï¼ˆ",
        "charlesar",
        "Ã¡",
        "nguiz",
        "ï¼‰",
        "ï¼Œ",
        "1989",
        "å¹´",
        "4",
        "æœˆ",
        "17",
        "æ—¥å‡º",
        "ç”Ÿäº",
        "æ™ºåˆ©",
        "åœ£åœ°äºšå“¥",
        "ï¼Œ",
        "æ™ºåˆ©",
        "èŒä¸š",
        "è¶³çƒ",
        "è¿åŠ¨å‘˜",
        "ï¼Œ",
        "å¸èŒ",
        "ä¸­åœº",
        "ï¼Œ",
        "æ•ˆåŠ›",
        "äº",
        "å¾·å›½",
        "è¶³çƒ",
        "ç”²çº§è”èµ›",
        "å‹’æ²ƒåº“æ£®",
        "è¶³çƒ",
        "ä¿±ä¹éƒ¨"
    ],
    "bert_tokens": null,
    "entity_list": [
        "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯",
        "åœ£åœ°äºšå“¥",
        "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯",
        "1989å¹´4æœˆ17æ—¥"
    ],
    "gold_answer": [
        [
            "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯",
            "å‡ºç”Ÿåœ°",
            "åœ£åœ°äºšå“¥"
        ],
        [
            "æŸ¥å°”æ–¯Â·é˜¿å…°åŸºæ–¯",
            "å‡ºç”Ÿæ—¥æœŸ",
            "1989å¹´4æœˆ17æ—¥"
        ]
    ]
}
p_ids:  tensor([0])
batch_char_ids:  tensor([[1125,  204,  163,   83,  437,  419,  321,  163,   54,  122,  209,   49,
           92,  132,   57,   85,   49,   92, 2927,   80,  263,  221,   69,  974,
           55,    3,    5,   13,   28,   13,   10,   46,   21,    5,   29,   32,
           16,   26,   20,  604,  301,  860,  133,  213,  734,    3,  604,  301,
          334,   37,  412,  186,  379,  138,   95,    3,   59,  334,   17,  217,
            3,  549,  198,   20,  219,   22,  412,  186,  986,  352,  281,  632,
         1110, 1306, 1368,  707,  412,  186, 1183,  136,   74]])
batch_word_ids:  tensor([[ 5085,  5085,  5085,    21,  6975,  6975, 21843, 21843,    14,     0,
             0,     0,     0,     0,     0,     0,     0,     0,  4769,     0,
             0,     0,     0,     0,    15,     1,   398,   398,   398,   398,
             7,    80,     8,   415,   415,   273,   273,    61,    61,  3445,
          3445, 12763, 12763, 12763, 12763,     1,  3445,  3445,   411,   411,
           188,   188,   180,   180,   180,     1,   643,   643,   735,   735,
             1,   193,   193,    10,   702,   702,   188,   188,  8287,  8287,
          8287,  8287, 41895, 41895, 41895, 41895,   188,   188,   515,   515,
           515]])
example:  Example: 
{
    "p_id": 2,
    "context": "ã€Šç¦»å¼€ã€‹æ˜¯ç”±å¼ å®‡è°±æ›²ï¼Œæ¼”å”±",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "ç¦»å¼€",
        "ã€‹",
        "æ˜¯",
        "ç”±",
        "å¼ å®‡",
        "è°±æ›²",
        "ï¼Œ",
        "æ¼”å”±"
    ],
    "bert_tokens": null,
    "entity_list": [
        "ç¦»å¼€",
        "å¼ å®‡",
        "ç¦»å¼€",
        "å¼ å®‡"
    ],
    "gold_answer": [
        [
            "ç¦»å¼€",
            "æ­Œæ‰‹",
            "å¼ å®‡"
        ],
        [
            "ç¦»å¼€",
            "ä½œæ›²",
            "å¼ å®‡"
        ]
    ]
}
p_ids:  tensor([1])
batch_char_ids:  tensor([[  7, 690, 188,   8,   6,  41,  86, 577, 941,  44,   3,  23, 100]])
batch_word_ids:  tensor([[   3, 1186, 1186,    4,    5,   13, 3745, 3745,  460,  460,    1,   43,
           43]])
example:  Example: 
{
    "p_id": 3,
    "context": "ã€Šæ„¤æ€’çš„å”åƒ§ã€‹ç”±åŒ—äº¬å´æ„æ³¢å½±è§†æ–‡åŒ–å·¥ä½œå®¤ä¸ä¼˜é…·ç”µè§†å‰§é¢‘é“è”åˆåˆ¶ä½œï¼Œæ•…äº‹ä»¥å–œå‰§å…ƒç´ ä¸ºä¸»ï¼Œè®²è¿°å”åƒ§ä¸ä½›ç¥–æ‰“ç‰Œï¼Œå¾—ç½ªäº†ä½›ç¥–ï¼Œè¢«è¸¢ä¸‹äººé—´å†æ¸¡ä¹ä¹å…«åä¸€éš¾çš„æ•…äº‹",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "æ„¤æ€’",
        "çš„",
        "å”åƒ§",
        "ã€‹",
        "ç”±",
        "åŒ—äº¬",
        "å´æ„æ³¢",
        "å½±è§†æ–‡åŒ–",
        "å·¥ä½œå®¤",
        "ä¸",
        "ä¼˜é…·",
        "ç”µè§†å‰§",
        "é¢‘é“",
        "è”åˆ",
        "åˆ¶ä½œ",
        "ï¼Œ",
        "æ•…äº‹",
        "ä»¥",
        "å–œå‰§",
        "å…ƒç´ ",
        "ä¸ºä¸»",
        "ï¼Œ",
        "è®²è¿°",
        "å”åƒ§",
        "ä¸",
        "ä½›ç¥–",
        "æ‰“ç‰Œ",
        "ï¼Œ",
        "å¾—ç½ª",
        "äº†",
        "ä½›ç¥–",
        "ï¼Œ",
        "è¢«",
        "è¸¢",
        "ä¸‹",
        "äººé—´",
        "å†æ¸¡",
        "ä¹ä¹å…«åä¸€",
        "éš¾",
        "çš„",
        "æ•…äº‹"
    ],
    "bert_tokens": null,
    "entity_list": [
        "æ„¤æ€’çš„å”åƒ§",
        "åŒ—äº¬å´æ„æ³¢å½±è§†æ–‡åŒ–å·¥ä½œå®¤",
        "æ„¤æ€’çš„å”åƒ§",
        "å´æ„æ³¢"
    ],
    "gold_answer": [
        [
            "æ„¤æ€’çš„å”åƒ§",
            "å‡ºå“å…¬å¸",
            "åŒ—äº¬å´æ„æ³¢å½±è§†æ–‡åŒ–å·¥ä½œå®¤"
        ],
        [
            "æ„¤æ€’çš„å”åƒ§",
            "å¯¼æ¼”",
            "å´æ„æ³¢"
        ]
    ]
}
p_ids:  tensor([2])
batch_char_ids:  tensor([[   7, 2676, 1866,    4,  444, 2137,    8,   41,   84,  140,  380,  445,
          561,   76,   65,   47,  199,   70,   14,  669,  113,  657, 1384,   48,
           65,   35, 1031,  264,  281,  182,  180,   14,    3,  416,  157,  145,
          338,   35,  323, 1001,   51,   42,    3,  609,  674,  444, 2137,  113,
         1100,  499,  484,  642,    3,  212, 1327,   40, 1100,  499,    3,  295,
         2868,  194,   18,  335,  506, 1749,  605,  605,  629,  267,   15,  827,
            4,  416,  157]])
batch_word_ids:  tensor([[    3,  5222,  5222,     2,  4963,  4963,     4,    13,    74,    74,
             0,     0,     0,   727,   727,   727,   727,   816,   816,   816,
            27,  2786,  2786,    52,    52,    52,  1501,  1501,   164,   164,
           113,   113,     1,   151,   151,   116,   464,   464,  1964,  1964,
          1143,  1143,     1,   318,   318,  4963,  4963,    27,     0,     0,
             0,     0,     1, 16397, 16397,    12,     0,     0,     1,    78,
          9533,   233,  2026,  2026,     0,     0, 25410, 25410, 25410, 25410,
         25410,  2778,     2,   151,   151]])
example:  Example: 
{
    "p_id": 4,
    "context": "ææ²»å³ä½åï¼Œè§æ·‘å¦ƒå—å® ï¼Œç‹çš‡åä¸ºäº†æ’æŒ¤è§æ·‘å¦ƒï¼Œç­”åº”ææ²»è®©èº«åœ¨æ„Ÿä¸šå¯ºçš„æ­¦åˆ™å¤©ç»­èµ·å¤´å‘ï¼Œé‡æ–°çº³å…¥åå®«",
    "raw_context": null,
    "text_word": [
        "ææ²»",
        "å³ä½",
        "å",
        "ï¼Œ",
        "è§æ·‘å¦ƒ",
        "å—å® ",
        "ï¼Œ",
        "ç‹çš‡å",
        "ä¸ºäº†",
        "æ’æŒ¤",
        "è§æ·‘å¦ƒ",
        "ï¼Œ",
        "ç­”åº”",
        "ææ²»",
        "è®©",
        "èº«",
        "åœ¨",
        "æ„Ÿä¸š",
        "å¯º",
        "çš„",
        "æ­¦åˆ™å¤©",
        "ç»­èµ·",
        "å¤´å‘",
        "ï¼Œ",
        "é‡æ–°",
        "çº³å…¥",
        "åå®«"
    ],
    "bert_tokens": null,
    "entity_list": [
        "ææ²»",
        "è§æ·‘å¦ƒ",
        "è§æ·‘å¦ƒ",
        "ææ²»"
    ],
    "gold_answer": [
        [
            "ææ²»",
            "å¦»å­",
            "è§æ·‘å¦ƒ"
        ],
        [
            "è§æ·‘å¦ƒ",
            "ä¸ˆå¤«",
            "ææ²»"
        ]
    ]
}
p_ids:  tensor([3])
batch_char_ids:  tensor([[ 101,  462,  898,  153,   82,    3, 1137, 1330, 1009,  528, 1380,    3,
           81,  521,   82,   51,   40, 1111, 3203, 1137, 1330, 1009,    3, 1741,
          612,  101,  462,  423,  232,   25,  375,   37, 1720,    4,  311,  857,
           89,  625,  215,  472,   73,    3,  234,  110,  673,  210,   82,  807]])
batch_word_ids:  tensor([[ 6798,  6798,  6303,  6303,    89,     1,     0,     0,     0, 21875,
         21875,     1, 20569, 20569, 20569,   438,   438, 23771, 23771,     0,
             0,     0,     1,  6896,  6896,  6798,  6798,   106,  4210,     9,
             0,     0,  4284,     2,  1482,  1482,  1482,     0,     0,  6635,
          6635,     1,  1433,  1433, 15573, 15573,  3265,  3265]])
example:  Example: 
{
    "p_id": 5,
    "context": "ã€Šå·¥ä¸š4.0ã€‹æ˜¯2015å¹´æœºæ¢°å·¥ä¸šå‡ºç‰ˆç¤¾å‡ºç‰ˆçš„å›¾ä¹¦ï¼Œä½œè€…æ˜¯ï¼ˆå¾·ï¼‰é˜¿å°”å†¯æ–¯Â·æ³¢ç‰¹éœå¤«ï¼Œæ©æ–¯ç‰¹Â·å®‰å¾·é›·äºšæ–¯Â·å“ˆç‰¹æ›¼",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "å·¥ä¸š",
        "4.0",
        "ã€‹",
        "æ˜¯",
        "2015",
        "å¹´",
        "æœºæ¢°",
        "å·¥ä¸š",
        "å‡ºç‰ˆç¤¾",
        "å‡ºç‰ˆ",
        "çš„",
        "å›¾ä¹¦",
        "ï¼Œ",
        "ä½œè€…",
        "æ˜¯",
        "ï¼ˆ",
        "å¾·",
        "ï¼‰",
        "é˜¿å°”",
        "å†¯æ–¯",
        "Â·",
        "æ³¢ç‰¹",
        "éœå¤«",
        "ï¼Œ",
        "æ©æ–¯ç‰¹",
        "Â·",
        "å®‰å¾·é›·",
        "äºšæ–¯",
        "Â·",
        "å“ˆç‰¹æ›¼"
    ],
    "bert_tokens": null,
    "entity_list": [
        "å·¥ä¸š4.0",
        "æ©æ–¯ç‰¹Â·å®‰å¾·é›·äºšæ–¯Â·å“ˆç‰¹æ›¼",
        "å·¥ä¸š4.0",
        "é˜¿å°”å†¯æ–¯Â·æ³¢ç‰¹éœå¤«",
        "å·¥ä¸š4.0",
        "æœºæ¢°å·¥ä¸šå‡ºç‰ˆç¤¾"
    ],
    "gold_answer": [
        [
            "å·¥ä¸š4.0",
            "ä½œè€…",
            "æ©æ–¯ç‰¹Â·å®‰å¾·é›·äºšæ–¯Â·å“ˆç‰¹æ›¼"
        ],
        [
            "å·¥ä¸š4.0",
            "ä½œè€…",
            "é˜¿å°”å†¯æ–¯Â·æ³¢ç‰¹éœå¤«"
        ],
        [
            "å·¥ä¸š4.0",
            "å‡ºç‰ˆç¤¾",
            "æœºæ¢°å·¥ä¸šå‡ºç‰ˆç¤¾"
        ]
    ]
}
p_ids:  tensor([4])
batch_char_ids:  tensor([[   7,   70,   37,   46,  400,    9,    8,    6,   12,    9,    5,   39,
           10,  339, 1025,   70,   37,   16,   30,   71,   16,   30,    4,   88,
           53,    3,   14,   50,    6,   54,  219,   55,  437,  204,  910,  163,
           83,  561,  211,  875,  394,    3,  571,  163,  211,   83,  174,  219,
          589,  213,  163,   83,  663,  211,  905]])
batch_word_ids:  tensor([[    3,   313,   313,     0,     0,     0,     4,     5,   194,   194,
           194,   194,     7,   667,   667,   313,   313,    39,    39,    39,
            20,    20,     2,    25,    25,     1,    16,    16,     5,    14,
           978,    15, 14630, 14630,     0,     0,    21, 13565, 13565, 29992,
         29992,     1, 32112, 32112, 32112,    21, 18568, 18568, 18568, 20024,
         20024,    21,     0,     0,     0]])
example:  Example: 
{
    "p_id": 6,
    "context": "å‘¨ä½›æµ·è¢«æ•å…¥ç‹±ä¹‹åï¼Œå…¶å¦»æ¨æ·‘æ…§æ•£å°½å®¶äº§è¯·è’‹ä»‹çŸ³æªä¸‹ç•™äººï¼Œäºæ˜¯å‘¨ä½›æµ·ä»æ­»åˆ‘å˜ä¸ºæ— æœŸï¼Œä¸è¿‡æ­¤äººæˆ–è®¸ä½œæ¶å¤šç«¯ï¼Œæ”¹åˆ¤æ²¡å¤šä¹…ä¾¿ç—…é€äºç›‘ç‹±ï¼Œæ®æ‚‰æ˜¯å¿ƒè„ç—…å‘ä½œ",
    "raw_context": null,
    "text_word": [
        "å‘¨ä½›æµ·",
        "è¢«æ•",
        "å…¥ç‹±",
        "ä¹‹å",
        "ï¼Œ",
        "å…¶å¦»",
        "æ¨æ·‘",
        "æ…§æ•£",
        "å°½",
        "å®¶äº§",
        "è¯·",
        "è’‹ä»‹çŸ³",
        "æªä¸‹",
        "ç•™äºº",
        "ï¼Œ",
        "äºæ˜¯",
        "å‘¨ä½›æµ·",
        "ä»",
        "æ­»åˆ‘",
        "å˜ä¸º",
        "æ— æœŸ",
        "ï¼Œ",
        "ä¸è¿‡",
        "æ­¤äºº",
        "æˆ–è®¸",
        "ä½œæ¶å¤šç«¯",
        "ï¼Œ",
        "æ”¹åˆ¤",
        "æ²¡å¤šä¹…",
        "ä¾¿",
        "ç—…é€",
        "äº",
        "ç›‘ç‹±",
        "ï¼Œ",
        "æ®æ‚‰",
        "æ˜¯",
        "å¿ƒè„ç—…",
        "å‘ä½œ"
    ],
    "bert_tokens": null,
    "entity_list": [
        "å‘¨ä½›æµ·",
        "æ¨æ·‘æ…§",
        "æ¨æ·‘æ…§",
        "å‘¨ä½›æµ·"
    ],
    "gold_answer": [
        [
            "å‘¨ä½›æµ·",
            "å¦»å­",
            "æ¨æ·‘æ…§"
        ],
        [
            "æ¨æ·‘æ…§",
            "ä¸ˆå¤«",
            "å‘¨ä½›æµ·"
        ]
    ]
}
p_ids:  tensor([5])
batch_char_ids:  tensor([[ 242, 1100,   98,  295, 1945,  210, 2077,   75,   82,    3,  250,  646,
          265, 1330,  831, 1432, 1184,   52,  195, 1039,  948,  289,  463, 1769,
          194,  810,   18,    3,   20,    6,  242, 1100,   98,  290,  809, 1664,
          630,   51,  282,  307,    3,   63,  226,  492,   18, 1098,  518,   14,
         1479,  158, 1367,    3,  440, 1462,  427,  158,  973,  994, 1033, 1656,
           20,  452, 2077,    3,  650, 1431,    6,  156, 2753, 1033,   73,   14]])
batch_word_ids:  tensor([[28461, 28461, 28461, 13043, 13043, 13661, 13661,   214,   214,     1,
         12498, 12498,     0,     0,     0,     0,  3940, 23515, 23515,  1022,
          2846,  2846,  2846,     0,     0,     0,     0,     1,  1105,  1105,
         28461, 28461, 28461,   129, 28817, 28817, 25736, 25736,     0,     0,
             1,   557,   557, 12491, 12491,  2675,  2675,     0,     0,     0,
             0,     1,     0,     0, 15403, 15403, 15403,   695,  6329,  6329,
            10,  5831,  5831,     1,  2503,  2503,     5, 18654, 18654, 18654,
         23869, 23869]])
example:  Example: 
{
    "p_id": 7,
    "context": "ã€Šæçƒˆé’§è‡ªè¿°ã€‹æ˜¯2011å¹´11æœˆ1æ—¥äººæ°‘æ—¥æŠ¥å‡ºç‰ˆç¤¾å‡ºç‰ˆçš„å›¾ä¹¦ï¼Œä½œè€…æ˜¯æçƒˆé’§",
    "raw_context": null,
    "text_word": [
        "ã€Š",
        "æçƒˆé’§",
        "è‡ªè¿°",
        "ã€‹",
        "æ˜¯",
        "2011",
        "å¹´",
        "11",
        "æœˆ",
        "1",
        "æ—¥",
        "äººæ°‘æ—¥æŠ¥",
        "å‡ºç‰ˆç¤¾",
        "å‡ºç‰ˆ",
        "çš„",
        "å›¾ä¹¦",
        "ï¼Œ",
        "ä½œè€…",
        "æ˜¯",
        "æçƒˆé’§"
    ],
    "bert_tokens": null,
    "entity_list": [
        "æçƒˆé’§è‡ªè¿°",
        "æçƒˆé’§",
        "æçƒˆé’§è‡ªè¿°",
        "äººæ°‘æ—¥æŠ¥å‡ºç‰ˆç¤¾"
    ],
    "gold_answer": [
        [
            "æçƒˆé’§è‡ªè¿°",
            "ä½œè€…",
            "æçƒˆé’§"
        ],
        [
            "æçƒˆé’§è‡ªè¿°",
            "å‡ºç‰ˆç¤¾",
            "äººæ°‘æ—¥æŠ¥å‡ºç‰ˆç¤¾"
        ]
    ]
}
p_ids:  tensor([6])
batch_char_ids:  tensor([[   7,  101, 1138, 1436,  125,  674,    8,    6,   12,    9,    5,    5,
           10,    5,    5,   21,    5,   32,   18,  164,   32,  661,   16,   30,
           71,   16,   30,    4,   88,   53,    3,   14,   50,    6,  101, 1138,
         1436]])
batch_word_ids:  tensor([[   3,    0,    0,    0, 9541, 9541,    4,    5,  108,  108,  108,  108,
            7,   91,   91,    8,   23,   18, 8063, 8063, 8063, 8063,   39,   39,
           39,   20,   20,    2,   25,   25,    1,   16,   16,    5,    0,    0,
            0]])
example:  Example: 
{
    "p_id": 8,
    "context": "é™¤æ¼”è‰ºäº‹ä¸šå¤–ï¼Œæå†°å†°çƒ­å¿ƒå…¬ç›Šï¼Œå‘èµ·å¹¶äº²è‡ªå‚ä¸å¤šé¡¹ç¯ä¿æ…ˆå–„æ´»åŠ¨ï¼Œç§¯ææŠ•èº«å…¶ä¸­ï¼Œèº«ä½“åŠ›è¡Œæ‹…èµ·äº†å›é¦ˆç¤¾ä¼šçš„è´£ä»»äº02å¹´å‡ºæ¼”ã€Šå°‘å¹´åŒ…é’å¤©ã€‹ï¼Œè¿›å…¥å¤§å®¶è§†çº¿",
    "raw_context": null,
    "text_word": [
        "é™¤",
        "æ¼”è‰ºäº‹ä¸š",
        "å¤–",
        "ï¼Œ",
        "æå†°å†°",
        "çƒ­å¿ƒ",
        "å…¬ç›Š",
        "ï¼Œ",
        "å‘èµ·",
        "å¹¶",
        "äº²è‡ª",
        "å‚ä¸",
        "å¤šé¡¹",
        "ç¯ä¿",
        "æ…ˆå–„",
        "æ´»åŠ¨",
        "ï¼Œ",
        "ç§¯æ",
        "æŠ•èº«",
        "å…¶ä¸­",
        "ï¼Œ",
        "èº«ä½“åŠ›è¡Œ",
        "æ‹…èµ·",
        "äº†",
        "å›é¦ˆ",
        "ç¤¾ä¼š",
        "çš„",
        "è´£ä»»",
        "äº",
        "02",
        "å¹´",
        "å‡ºæ¼”",
        "ã€Š",
        "å°‘å¹´",
        "åŒ…é’å¤©",
        "ã€‹",
        "ï¼Œ",
        "è¿›å…¥",
        "å¤§å®¶",
        "è§†çº¿"
    ],
    "bert_tokens": null,
    "entity_list": [
        "å°‘å¹´åŒ…é’å¤©",
        "æå†°å†°"
    ],
    "gold_answer": [
        [
            "å°‘å¹´åŒ…é’å¤©",
            "ä¸»æ¼”",
            "æå†°å†°"
        ]
    ]
}
p_ids:  tensor([7])
batch_char_ids:  tensor([[1149,   23,  251,  157,   37,  341,    3,  101,  722,  722,  429,  156,
           38, 1296,    3,   73,  215,  287,  383,  125,  227,  113,  158,  856,
          710,  522, 1387, 1020,  421,  138,    3,  628,  695,  598,  232,  250,
           17,    3,  232,  254,  198,  105,  569,  215,   40,  454, 3973,   71,
          121,    4,  909,  147,   20,    9,   12,   10,   16,   23,    7,  313,
           10,  712,  261,   89,    8,    3,  384,  210,   24,   52,   65,  588]])
batch_word_ids:  tensor([[ 4281,  6406,  6406,  6406,  6406,  1257,     1,  7540,  7540,  7540,
         14432, 14432,  3250,  3250,     1,  3186,  3186,    86,  1134,  1134,
           733,   733,     0,     0,  1736,  1736,  5651,  5651,   981,   981,
             1,  3084,  3084, 13148, 13148,   248,   248,     1,     0,     0,
             0,     0, 28218, 28218,    12, 23562, 23562,   624,   624,     2,
          5046,  5046,    10,   642,   642,     7,   162,   162,     3,   646,
           646,  5584,  5584,  5584,     4,     1,   485,   485,   257,   257,
          4229,  4229]])

                  [A============================================
dev/entity_em: 0,	entity_pred_num&entity_gold_num: 207	21 
dev/entity_f1: 0.0, 	entity_precision: 0.0,	entity_recall: 0.0 
============================================
dev/em: 1e-10,	pre&gold: 377.0000000001	16.000000000100002 
dev/f1: 5.089058524170439e-11, 	Precision: 2.652519893898501e-11,	Recall: 6.249999999960937e-10 
